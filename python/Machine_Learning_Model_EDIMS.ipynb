{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGhXUCDgm4tT"
      },
      "source": [
        "#EDIMS Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ5BcrnjoE0b"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDxfcyoEndaT",
        "outputId": "3b7c7552-2f9a-47f9-d5f4-b85bdcb8fcb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "# put all installation here\n",
        "! pip install mltu==0.1.3\n",
        "! pip install lanms-neo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aMrmg_vBmZmI"
      },
      "outputs": [],
      "source": [
        "# put all import here\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# Text Detection\n",
        "import glob\n",
        "import sys\n",
        "import csv\n",
        "import cv2\n",
        "import time\n",
        "import os\n",
        "import argparse\n",
        "import itertools\n",
        "from multiprocessing import Pool\n",
        "import threading\n",
        "import numpy as np\n",
        "import scipy.optimize\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as Patches\n",
        "from shapely.geometry import Polygon\n",
        "from lanms import merge_quadrangle_n9 as la_nms\n",
        "\n",
        "# Text Recognition\n",
        "import typing\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from mltu.model_utils import residual_block\n",
        "from datetime import datetime\n",
        "from mltu.configs import BaseModelConfigs\n",
        "from tqdm import tqdm\n",
        "try: [tf.config.experimental.set_memory_growth(gpu, True) for gpu in tf.config.experimental.list_physical_devices(\"GPU\")]\n",
        "except: pass\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from mltu.dataProvider import DataProvider\n",
        "from mltu.preprocessors import ImageReader\n",
        "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding\n",
        "from mltu.losses import CTCloss\n",
        "from mltu.callbacks import Model2onnx, TrainLogger\n",
        "from mltu.metrics import CWERMetric\n",
        "import json\n",
        "from itertools import groupby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QfagFyuwfMrk",
        "outputId": "facbc2fa-74d1-417d-8cee-2608253baae4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Product Dataset\n",
        "! gdown 1Uxh4D-p_rwYhXn5D4hRuyckpWoGkJolv\n",
        "! gdown 1kpnchVYWv7fVtwN55CbnPNrn5br-9aS3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4fG4rPjNSqHf",
        "outputId": "ad6bc397-81ff-46bf-b68a-1d25cf3a4b58"
      },
      "outputs": [],
      "source": [
        "# Date Dataset\n",
        "! gdown 1bA3Wk9HmabxXPUADK4nbeVqUCjTVaAqh\n",
        "! gdown 1PEChAstAXvXBSYEbbpuquR7Q7Wei8i-p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dmy3hOx0nGFL",
        "outputId": "50b01d90-286d-4887-d96c-015b655ec4da"
      },
      "outputs": [],
      "source": [
        "! unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sav93cUsuSYx"
      },
      "source": [
        "# Text Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rax-yBzhudMf"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZOk-wsEzgMEY"
      },
      "outputs": [],
      "source": [
        "# Loss Function\n",
        "def dice_loss(overly_small_text_region_training_mask, text_region_boundary_training_mask, loss_weight, small_text_weight, score_y_true, score_y_pred):\n",
        "  eps = 1e-5\n",
        "  _training_mask = tf.minimum(overly_small_text_region_training_mask + small_text_weight, 1) * text_region_boundary_training_mask\n",
        "  intersection = tf.reduce_sum(score_y_true * score_y_pred * _training_mask)\n",
        "  union = tf.reduce_sum(score_y_true * _training_mask) + tf.reduce_sum(score_y_pred * _training_mask) + eps\n",
        "  loss = 1. - (2. * intersection / union)\n",
        "\n",
        "  return loss * loss_weight\n",
        "\n",
        "def rbox_loss(overly_small_text_region_training_mask, text_region_boundary_training_mask, small_text_weight, target_score_map, geo_y_true, geo_y_pred):\n",
        "  # d1 -> top, d2->right, d3->bottom, d4->left\n",
        "  d1_gt, d2_gt, d3_gt, d4_gt, theta_gt = tf.split(value=geo_y_true, num_or_size_splits=5, axis=3)\n",
        "  d1_pred, d2_pred, d3_pred, d4_pred, theta_pred = tf.split(value=geo_y_pred, num_or_size_splits=5, axis=3)\n",
        "  area_gt = (d1_gt + d3_gt) * (d2_gt + d4_gt)\n",
        "  area_pred = (d1_pred + d3_pred) * (d2_pred + d4_pred)\n",
        "  w_union = tf.minimum(d2_gt, d2_pred) + tf.minimum(d4_gt, d4_pred)\n",
        "  h_union = tf.minimum(d1_gt, d1_pred) + tf.minimum(d3_gt, d3_pred)\n",
        "  area_intersect = w_union * h_union\n",
        "  area_union = area_gt + area_pred - area_intersect\n",
        "  L_AABB = -tf.math.log((area_intersect + 1.0) / (area_union + 1.0))\n",
        "  L_theta = 1 - tf.cos(theta_pred - theta_gt)\n",
        "  L_g = L_AABB + 20 * L_theta\n",
        "  _training_mask = tf.minimum(overly_small_text_region_training_mask + small_text_weight, 1) * text_region_boundary_training_mask\n",
        "\n",
        "  return tf.reduce_mean(L_g * target_score_map * _training_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "txrgJ4MIgOnA"
      },
      "outputs": [],
      "source": [
        "# Load File\n",
        "\n",
        "def get_images(data_path):\n",
        "  files = []\n",
        "  with open(data_path+\"/annotations.json\") as f:\n",
        "    data = json.load(f)\n",
        "    for line in data:\n",
        "      files.append(f\"{data_path}/images/{line}\")\n",
        "  return files\n",
        "\n",
        "\n",
        "def load_annotation(annotation_path,p):\n",
        "  text_polys = []\n",
        "  text_tags = []\n",
        "  with open(annotation_path +\"/annotations.json\") as f:\n",
        "    data = json.load(f)\n",
        "    for obj in data[p][\"ann\"]:\n",
        "      x1, x2, y1, y2 = obj[\"bbox\"]\n",
        "      text_polys.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])\n",
        "      if \"transcription\" in obj:\n",
        "        text_tags.append(False)\n",
        "      else:\n",
        "        text_tags.append(True)\n",
        "    return np.array(text_polys, dtype=np.float32), np.array(text_tags, dtype=bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IWAHV2s-t9WC"
      },
      "outputs": [],
      "source": [
        "# Check and Validate Polygon\n",
        "def polygon_area(poly):\n",
        "  edge = [\n",
        "    (poly[1][0] - poly[0][0]) * (poly[1][1] + poly[0][1]),\n",
        "    (poly[2][0] - poly[1][0]) * (poly[2][1] + poly[1][1]),\n",
        "    (poly[3][0] - poly[2][0]) * (poly[3][1] + poly[2][1]),\n",
        "    (poly[0][0] - poly[3][0]) * (poly[0][1] + poly[3][1])\n",
        "  ]\n",
        "  return np.sum(edge)/2.\n",
        "\n",
        "\n",
        "def check_and_validate_polys(FLAGS, polys, tags, size):\n",
        "  (h, w) = size\n",
        "  if polys.shape[0] == 0:\n",
        "    return polys\n",
        "  polys[:, :, 0] = np.clip(polys[:, :, 0], 0, w-1)\n",
        "  polys[:, :, 1] = np.clip(polys[:, :, 1], 0, h-1)\n",
        "\n",
        "  validated_polys = []\n",
        "  validated_tags = []\n",
        "  for poly, tag in zip(polys, tags):\n",
        "    p_area = polygon_area(poly)\n",
        "    if abs(p_area) < 1:\n",
        "      # print poly\n",
        "      if not FLAGS.suppress_warnings_and_error_messages:\n",
        "        print('invalid poly')\n",
        "      continue\n",
        "    if p_area > 0:\n",
        "      if not FLAGS.suppress_warnings_and_error_messages:\n",
        "        print('poly in wrong direction')\n",
        "      poly = poly[(0, 3, 2, 1), :]\n",
        "    validated_polys.append(poly)\n",
        "    validated_tags.append(tag)\n",
        "  return np.array(validated_polys), np.array(validated_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dcME4qc3t_GO"
      },
      "outputs": [],
      "source": [
        "# Crop and Shrink Polygon\n",
        "def crop_area(FLAGS, im, polys, tags, crop_background=False, max_tries=50):\n",
        "  h, w, _ = im.shape\n",
        "  pad_h = h//10\n",
        "  pad_w = w//10\n",
        "  h_array = np.zeros((h + pad_h*2), dtype=np.int32)\n",
        "  w_array = np.zeros((w + pad_w*2), dtype=np.int32)\n",
        "  for poly in polys:\n",
        "    poly = np.round(poly, decimals=0).astype(np.int32)\n",
        "    minx = np.min(poly[:, 0])\n",
        "    maxx = np.max(poly[:, 0])\n",
        "    w_array[minx+pad_w:maxx+pad_w] = 1\n",
        "    miny = np.min(poly[:, 1])\n",
        "    maxy = np.max(poly[:, 1])\n",
        "    h_array[miny+pad_h:maxy+pad_h] = 1\n",
        "  # ensure the cropped area not across a text\n",
        "  h_axis = np.where(h_array == 0)[0]\n",
        "  w_axis = np.where(w_array == 0)[0]\n",
        "  if len(h_axis) == 0 or len(w_axis) == 0:\n",
        "    return im, polys, tags\n",
        "  for i in range(max_tries):\n",
        "    xx = np.random.choice(w_axis, size=2)\n",
        "    xmin = np.min(xx) - pad_w\n",
        "    xmax = np.max(xx) - pad_w\n",
        "    xmin = np.clip(xmin, 0, w-1)\n",
        "    xmax = np.clip(xmax, 0, w-1)\n",
        "    yy = np.random.choice(h_axis, size=2)\n",
        "    ymin = np.min(yy) - pad_h\n",
        "    ymax = np.max(yy) - pad_h\n",
        "    ymin = np.clip(ymin, 0, h-1)\n",
        "    ymax = np.clip(ymax, 0, h-1)\n",
        "    if xmax - xmin < FLAGS.min_crop_side_ratio*w or ymax - ymin < FLAGS.min_crop_side_ratio*h:\n",
        "      # area too small\n",
        "      continue\n",
        "    if polys.shape[0] != 0:\n",
        "      poly_axis_in_area = (polys[:, :, 0] >= xmin) & (polys[:, :, 0] <= xmax) \\\n",
        "                          & (polys[:, :, 1] >= ymin) & (polys[:, :, 1] <= ymax)\n",
        "      selected_polys = np.where(np.sum(poly_axis_in_area, axis=1) == 4)[0]\n",
        "    else:\n",
        "      selected_polys = []\n",
        "    if len(selected_polys) == 0:\n",
        "      # no text in this area\n",
        "      if crop_background:\n",
        "        return im[ymin:ymax+1, xmin:xmax+1, :], polys[selected_polys], tags[selected_polys]\n",
        "      else:\n",
        "        continue\n",
        "    im = im[ymin:ymax+1, xmin:xmax+1, :]\n",
        "    polys = polys[selected_polys]\n",
        "    tags = tags[selected_polys]\n",
        "    polys[:, :, 0] -= xmin\n",
        "    polys[:, :, 1] -= ymin\n",
        "    return im, polys, tags\n",
        "\n",
        "  return im, polys, tags\n",
        "\n",
        "\n",
        "def shrink_poly(poly, r):\n",
        "  # shrink ratio\n",
        "  R = 0.3\n",
        "  # find the longer pair\n",
        "  if np.linalg.norm(poly[0] - poly[1]) + np.linalg.norm(poly[2] - poly[3]) > \\\n",
        "          np.linalg.norm(poly[0] - poly[3]) + np.linalg.norm(poly[1] - poly[2]):\n",
        "    # first move (p0, p1), (p2, p3), then (p0, p3), (p1, p2)\n",
        "    ## p0, p1\n",
        "    theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n",
        "    poly[0][0] += R * r[0] * np.cos(theta)\n",
        "    poly[0][1] += R * r[0] * np.sin(theta)\n",
        "    poly[1][0] -= R * r[1] * np.cos(theta)\n",
        "    poly[1][1] -= R * r[1] * np.sin(theta)\n",
        "    ## p2, p3\n",
        "    theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n",
        "    poly[3][0] += R * r[3] * np.cos(theta)\n",
        "    poly[3][1] += R * r[3] * np.sin(theta)\n",
        "    poly[2][0] -= R * r[2] * np.cos(theta)\n",
        "    poly[2][1] -= R * r[2] * np.sin(theta)\n",
        "    ## p0, p3\n",
        "    theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n",
        "    poly[0][0] += R * r[0] * np.sin(theta)\n",
        "    poly[0][1] += R * r[0] * np.cos(theta)\n",
        "    poly[3][0] -= R * r[3] * np.sin(theta)\n",
        "    poly[3][1] -= R * r[3] * np.cos(theta)\n",
        "    ## p1, p2\n",
        "    theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n",
        "    poly[1][0] += R * r[1] * np.sin(theta)\n",
        "    poly[1][1] += R * r[1] * np.cos(theta)\n",
        "    poly[2][0] -= R * r[2] * np.sin(theta)\n",
        "    poly[2][1] -= R * r[2] * np.cos(theta)\n",
        "  else:\n",
        "    ## p0, p3\n",
        "    # print poly\n",
        "    theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n",
        "    poly[0][0] += R * r[0] * np.sin(theta)\n",
        "    poly[0][1] += R * r[0] * np.cos(theta)\n",
        "    poly[3][0] -= R * r[3] * np.sin(theta)\n",
        "    poly[3][1] -= R * r[3] * np.cos(theta)\n",
        "    ## p1, p2\n",
        "    theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n",
        "    poly[1][0] += R * r[1] * np.sin(theta)\n",
        "    poly[1][1] += R * r[1] * np.cos(theta)\n",
        "    poly[2][0] -= R * r[2] * np.sin(theta)\n",
        "    poly[2][1] -= R * r[2] * np.cos(theta)\n",
        "    ## p0, p1\n",
        "    theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n",
        "    poly[0][0] += R * r[0] * np.cos(theta)\n",
        "    poly[0][1] += R * r[0] * np.sin(theta)\n",
        "    poly[1][0] -= R * r[1] * np.cos(theta)\n",
        "    poly[1][1] -= R * r[1] * np.sin(theta)\n",
        "    ## p2, p3\n",
        "    theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n",
        "    poly[3][0] += R * r[3] * np.cos(theta)\n",
        "    poly[3][1] += R * r[3] * np.sin(theta)\n",
        "    poly[2][0] -= R * r[2] * np.cos(theta)\n",
        "    poly[2][1] -= R * r[2] * np.sin(theta)\n",
        "  return poly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-rDnWeMyuBLj"
      },
      "outputs": [],
      "source": [
        "# Line Function\n",
        "def point_dist_to_line(p1, p2, p3):\n",
        "  # compute the distance from p3 to p1-p2\n",
        "  return np.linalg.norm(np.cross(p2 - p1, p1 - p3)) / np.linalg.norm(p2 - p1)\n",
        "\n",
        "\n",
        "def fit_line(p1, p2):\n",
        "  # fit a line ax+by+c = 0\n",
        "  if p1[0] == p1[1]:\n",
        "    return [1., 0., -p1[0]]\n",
        "  else:\n",
        "    [k, b] = np.polyfit(p1, p2, deg=1)\n",
        "    return [k, -1., b]\n",
        "\n",
        "\n",
        "def line_cross_point(FLAGS, line1, line2):\n",
        "  # line1 0= ax+by+c, compute the cross point of line1 and line2\n",
        "  if line1[0] != 0 and line1[0] == line2[0]:\n",
        "    if not FLAGS.suppress_warnings_and_error_messages:\n",
        "      print('Cross point does not exist')\n",
        "    return None\n",
        "  if line1[0] == 0 and line2[0] == 0:\n",
        "    if not FLAGS.suppress_warnings_and_error_messages:\n",
        "      print('Cross point does not exist')\n",
        "    return None\n",
        "  if line1[1] == 0:\n",
        "    x = -line1[2]\n",
        "    y = line2[0] * x + line2[2]\n",
        "  elif line2[1] == 0:\n",
        "    x = -line2[2]\n",
        "    y = line1[0] * x + line1[2]\n",
        "  else:\n",
        "    k1, _, b1 = line1\n",
        "    k2, _, b2 = line2\n",
        "    x = -(b1-b2)/(k1-k2)\n",
        "    y = k1*x + b1\n",
        "  return np.array([x, y], dtype=np.float32)\n",
        "\n",
        "\n",
        "def line_verticle(line, point):\n",
        "  # get the verticle line from line across point\n",
        "  if line[1] == 0:\n",
        "    verticle = [0, -1, point[1]]\n",
        "  else:\n",
        "    if line[0] == 0:\n",
        "      verticle = [1, 0, -point[0]]\n",
        "    else:\n",
        "      verticle = [-1./line[0], -1, point[1] - (-1/line[0] * point[0])]\n",
        "  return verticle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yyBWEcLZuCys"
      },
      "outputs": [],
      "source": [
        "# Rectangle Function\n",
        "def rectangle_from_parallelogram(FLAGS, poly):\n",
        "  p0, p1, p2, p3 = poly\n",
        "  angle_p0 = np.arccos(np.dot(p1-p0, p3-p0)/(np.linalg.norm(p0-p1) * np.linalg.norm(p3-p0)))\n",
        "  if angle_p0 < 0.5 * np.pi:\n",
        "    if np.linalg.norm(p0 - p1) > np.linalg.norm(p0-p3):\n",
        "      # p0 and p2\n",
        "      ## p0\n",
        "      p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n",
        "      p2p3_verticle = line_verticle(p2p3, p0)\n",
        "\n",
        "      new_p3 = line_cross_point(FLAGS, p2p3, p2p3_verticle)\n",
        "      ## p2\n",
        "      p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n",
        "      p0p1_verticle = line_verticle(p0p1, p2)\n",
        "\n",
        "      new_p1 = line_cross_point(FLAGS, p0p1, p0p1_verticle)\n",
        "      return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\n",
        "    else:\n",
        "      p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n",
        "      p1p2_verticle = line_verticle(p1p2, p0)\n",
        "\n",
        "      new_p1 = line_cross_point(FLAGS, p1p2, p1p2_verticle)\n",
        "      p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n",
        "      p0p3_verticle = line_verticle(p0p3, p2)\n",
        "\n",
        "      new_p3 = line_cross_point(FLAGS, p0p3, p0p3_verticle)\n",
        "      return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\n",
        "  else:\n",
        "    if np.linalg.norm(p0-p1) > np.linalg.norm(p0-p3):\n",
        "      # p1 and p3\n",
        "      ## p1\n",
        "      p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n",
        "      p2p3_verticle = line_verticle(p2p3, p1)\n",
        "\n",
        "      new_p2 = line_cross_point(FLAGS, p2p3, p2p3_verticle)\n",
        "      ## p3\n",
        "      p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n",
        "      p0p1_verticle = line_verticle(p0p1, p3)\n",
        "\n",
        "      new_p0 = line_cross_point(FLAGS, p0p1, p0p1_verticle)\n",
        "      return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)\n",
        "    else:\n",
        "      p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n",
        "      p0p3_verticle = line_verticle(p0p3, p1)\n",
        "\n",
        "      new_p0 = line_cross_point(FLAGS, p0p3, p0p3_verticle)\n",
        "      p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n",
        "      p1p2_verticle = line_verticle(p1p2, p3)\n",
        "\n",
        "      new_p2 = line_cross_point(FLAGS, p1p2, p1p2_verticle)\n",
        "      return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)\n",
        "\n",
        "\n",
        "def sort_rectangle(FLAGS, poly):\n",
        "  # sort the four coordinates of the polygon, points in poly should be sorted clockwise\n",
        "  # First find the lowest point\n",
        "  p_lowest = np.argmax(poly[:, 1])\n",
        "  if np.count_nonzero(poly[:, 1] == poly[p_lowest, 1]) == 2:\n",
        "    # if the bottom line is parallel to x-axis, then p0 must be the upper-left corner\n",
        "    p0_index = np.argmin(np.sum(poly, axis=1))\n",
        "    p1_index = (p0_index + 1) % 4\n",
        "    p2_index = (p0_index + 2) % 4\n",
        "    p3_index = (p0_index + 3) % 4\n",
        "    return poly[[p0_index, p1_index, p2_index, p3_index]], 0.\n",
        "  else:\n",
        "    # find the point that sits right to the lowest point\n",
        "    p_lowest_right = (p_lowest - 1) % 4\n",
        "    p_lowest_left = (p_lowest + 1) % 4\n",
        "    angle = np.arctan(-(poly[p_lowest][1] - poly[p_lowest_right][1])/(poly[p_lowest][0] - poly[p_lowest_right][0]))\n",
        "    # assert angle > 0\n",
        "    if angle <= 0:\n",
        "      if not FLAGS.suppress_warnings_and_error_messages:\n",
        "        print(angle, poly[p_lowest], poly[p_lowest_right])\n",
        "    if angle/np.pi * 180 > 45:\n",
        "      # 这个点为p2 - this point is p2\n",
        "      p2_index = p_lowest\n",
        "      p1_index = (p2_index - 1) % 4\n",
        "      p0_index = (p2_index - 2) % 4\n",
        "      p3_index = (p2_index + 1) % 4\n",
        "      return poly[[p0_index, p1_index, p2_index, p3_index]], -(np.pi/2 - angle)\n",
        "    else:\n",
        "      # 这个点为p3 - this point is p3\n",
        "      p3_index = p_lowest\n",
        "      p0_index = (p3_index + 1) % 4\n",
        "      p1_index = (p3_index + 2) % 4\n",
        "      p2_index = (p3_index + 3) % 4\n",
        "      return poly[[p0_index, p1_index, p2_index, p3_index]], angle\n",
        "\n",
        "\n",
        "def restore_rectangle_rbox(origin, geometry):\n",
        "  d = geometry[:, :4]\n",
        "  angle = geometry[:, 4]\n",
        "  # for angle > 0\n",
        "  origin_0 = origin[angle >= 0]\n",
        "  d_0 = d[angle >= 0]\n",
        "  angle_0 = angle[angle >= 0]\n",
        "  if origin_0.shape[0] > 0:\n",
        "    p = np.array([np.zeros(d_0.shape[0]), -d_0[:, 0] - d_0[:, 2],\n",
        "                  d_0[:, 1] + d_0[:, 3], -d_0[:, 0] - d_0[:, 2],\n",
        "                  d_0[:, 1] + d_0[:, 3], np.zeros(d_0.shape[0]),\n",
        "                  np.zeros(d_0.shape[0]), np.zeros(d_0.shape[0]),\n",
        "                  d_0[:, 3], -d_0[:, 2]])\n",
        "    p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n",
        "\n",
        "    rotate_matrix_x = np.array([np.cos(angle_0), np.sin(angle_0)]).transpose((1, 0))\n",
        "    rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n",
        "\n",
        "    rotate_matrix_y = np.array([-np.sin(angle_0), np.cos(angle_0)]).transpose((1, 0))\n",
        "    rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n",
        "\n",
        "    p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
        "    p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
        "\n",
        "    p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n",
        "\n",
        "    p3_in_origin = origin_0 - p_rotate[:, 4, :]\n",
        "    new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n",
        "    new_p1 = p_rotate[:, 1, :] + p3_in_origin\n",
        "    new_p2 = p_rotate[:, 2, :] + p3_in_origin\n",
        "    new_p3 = p_rotate[:, 3, :] + p3_in_origin\n",
        "\n",
        "    new_p_0 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n",
        "                              new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n",
        "  else:\n",
        "    new_p_0 = np.zeros((0, 4, 2))\n",
        "  # for angle < 0\n",
        "  origin_1 = origin[angle < 0]\n",
        "  d_1 = d[angle < 0]\n",
        "  angle_1 = angle[angle < 0]\n",
        "  if origin_1.shape[0] > 0:\n",
        "    p = np.array([-d_1[:, 1] - d_1[:, 3], -d_1[:, 0] - d_1[:, 2],\n",
        "                  np.zeros(d_1.shape[0]), -d_1[:, 0] - d_1[:, 2],\n",
        "                  np.zeros(d_1.shape[0]), np.zeros(d_1.shape[0]),\n",
        "                  -d_1[:, 1] - d_1[:, 3], np.zeros(d_1.shape[0]),\n",
        "                  -d_1[:, 1], -d_1[:, 2]])\n",
        "    p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n",
        "\n",
        "    rotate_matrix_x = np.array([np.cos(-angle_1), -np.sin(-angle_1)]).transpose((1, 0))\n",
        "    rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n",
        "\n",
        "    rotate_matrix_y = np.array([np.sin(-angle_1), np.cos(-angle_1)]).transpose((1, 0))\n",
        "    rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n",
        "\n",
        "    p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
        "    p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
        "\n",
        "    p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n",
        "\n",
        "    p3_in_origin = origin_1 - p_rotate[:, 4, :]\n",
        "    new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n",
        "    new_p1 = p_rotate[:, 1, :] + p3_in_origin\n",
        "    new_p2 = p_rotate[:, 2, :] + p3_in_origin\n",
        "    new_p3 = p_rotate[:, 3, :] + p3_in_origin\n",
        "\n",
        "    new_p_1 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n",
        "                              new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n",
        "  else:\n",
        "    new_p_1 = np.zeros((0, 4, 2))\n",
        "  return np.concatenate([new_p_0, new_p_1])\n",
        "\n",
        "\n",
        "def restore_rectangle(origin, geometry):\n",
        "  return restore_rectangle_rbox(origin, geometry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9SC3xzc3t_iq"
      },
      "outputs": [],
      "source": [
        "def generate_rbox(FLAGS, im_size, polys, tags):\n",
        "  h, w = im_size\n",
        "  shrinked_poly_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "  orig_poly_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "  score_map = np.zeros((h, w), dtype=np.uint8)\n",
        "  geo_map = np.zeros((h, w, 5), dtype=np.float32)\n",
        "  # mask used during traning, to ignore some hard areas\n",
        "  overly_small_text_region_training_mask = np.ones((h, w), dtype=np.uint8)\n",
        "  for poly_idx, poly_data in enumerate(zip(polys, tags)):\n",
        "    poly = poly_data[0]\n",
        "    tag = poly_data[1]\n",
        "\n",
        "    r = [None, None, None, None]\n",
        "    for i in range(4):\n",
        "      r[i] = min(np.linalg.norm(poly[i] - poly[(i + 1) % 4]),\n",
        "                 np.linalg.norm(poly[i] - poly[(i - 1) % 4]))\n",
        "    # score map\n",
        "    shrinked_poly = shrink_poly(poly.copy(), r).astype(np.int32)[np.newaxis, :, :]\n",
        "    cv2.fillPoly(score_map, shrinked_poly, 1)\n",
        "    cv2.fillPoly(shrinked_poly_mask, shrinked_poly, poly_idx + 1)\n",
        "    cv2.fillPoly(orig_poly_mask, poly.astype(np.int32)[np.newaxis, :, :], 1)\n",
        "    # if the poly is too small, then ignore it during training\n",
        "    poly_h = min(np.linalg.norm(poly[0] - poly[3]), np.linalg.norm(poly[1] - poly[2]))\n",
        "    poly_w = min(np.linalg.norm(poly[0] - poly[1]), np.linalg.norm(poly[2] - poly[3]))\n",
        "    if min(poly_h, poly_w) < FLAGS.min_text_size:\n",
        "      cv2.fillPoly(overly_small_text_region_training_mask, poly.astype(np.int32)[np.newaxis, :, :], 0)\n",
        "    if tag:\n",
        "      cv2.fillPoly(overly_small_text_region_training_mask, poly.astype(np.int32)[np.newaxis, :, :], 0)\n",
        "\n",
        "    xy_in_poly = np.argwhere(shrinked_poly_mask == (poly_idx + 1))\n",
        "    # if geometry == 'RBOX':\n",
        "    # generate a parallelogram for any combination of two vertices\n",
        "    fitted_parallelograms = []\n",
        "    for i in range(4):\n",
        "      p0 = poly[i]\n",
        "      p1 = poly[(i + 1) % 4]\n",
        "      p2 = poly[(i + 2) % 4]\n",
        "      p3 = poly[(i + 3) % 4]\n",
        "      edge = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n",
        "      backward_edge = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n",
        "      forward_edge = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n",
        "      if point_dist_to_line(p0, p1, p2) > point_dist_to_line(p0, p1, p3):\n",
        "        # parallel lines through p2\n",
        "        if edge[1] == 0:\n",
        "          edge_opposite = [1, 0, -p2[0]]\n",
        "        else:\n",
        "          edge_opposite = [edge[0], -1, p2[1] - edge[0] * p2[0]]\n",
        "      else:\n",
        "        # after p3\n",
        "        if edge[1] == 0:\n",
        "          edge_opposite = [1, 0, -p3[0]]\n",
        "        else:\n",
        "          edge_opposite = [edge[0], -1, p3[1] - edge[0] * p3[0]]\n",
        "      # move forward edge\n",
        "      new_p0 = p0\n",
        "      new_p1 = p1\n",
        "      new_p2 = p2\n",
        "      new_p3 = p3\n",
        "      new_p2 = line_cross_point(FLAGS, forward_edge, edge_opposite)\n",
        "      if point_dist_to_line(p1, new_p2, p0) > point_dist_to_line(p1, new_p2, p3):\n",
        "        # across p0\n",
        "        if forward_edge[1] == 0:\n",
        "          forward_opposite = [1, 0, -p0[0]]\n",
        "        else:\n",
        "          forward_opposite = [forward_edge[0], -1, p0[1] - forward_edge[0] * p0[0]]\n",
        "      else:\n",
        "        # across p3\n",
        "        if forward_edge[1] == 0:\n",
        "          forward_opposite = [1, 0, -p3[0]]\n",
        "        else:\n",
        "          forward_opposite = [forward_edge[0], -1, p3[1] - forward_edge[0] * p3[0]]\n",
        "      new_p0 = line_cross_point(FLAGS, forward_opposite, edge)\n",
        "      new_p3 = line_cross_point(FLAGS, forward_opposite, edge_opposite)\n",
        "      fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n",
        "      # or move backward edge\n",
        "      new_p0 = p0\n",
        "      new_p1 = p1\n",
        "      new_p2 = p2\n",
        "      new_p3 = p3\n",
        "      new_p3 = line_cross_point(FLAGS, backward_edge, edge_opposite)\n",
        "      if point_dist_to_line(p0, p3, p1) > point_dist_to_line(p0, p3, p2):\n",
        "        # across p1\n",
        "        if backward_edge[1] == 0:\n",
        "          backward_opposite = [1, 0, -p1[0]]\n",
        "        else:\n",
        "          backward_opposite = [backward_edge[0], -1, p1[1] - backward_edge[0] * p1[0]]\n",
        "      else:\n",
        "        # across p2\n",
        "        if backward_edge[1] == 0:\n",
        "          backward_opposite = [1, 0, -p2[0]]\n",
        "        else:\n",
        "          backward_opposite = [backward_edge[0], -1, p2[1] - backward_edge[0] * p2[0]]\n",
        "      new_p1 = line_cross_point(FLAGS, backward_opposite, edge)\n",
        "      new_p2 = line_cross_point(FLAGS, backward_opposite, edge_opposite)\n",
        "      fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n",
        "    areas = [Polygon(t).area for t in fitted_parallelograms]\n",
        "    parallelogram = np.array(fitted_parallelograms[np.argmin(areas)][:-1], dtype=np.float32)\n",
        "    # sort thie polygon\n",
        "    parallelogram_coord_sum = np.sum(parallelogram, axis=1)\n",
        "    min_coord_idx = np.argmin(parallelogram_coord_sum)\n",
        "    parallelogram = parallelogram[\n",
        "      [min_coord_idx, (min_coord_idx + 1) % 4, (min_coord_idx + 2) % 4, (min_coord_idx + 3) % 4]]\n",
        "\n",
        "    rectange = rectangle_from_parallelogram(FLAGS, parallelogram)\n",
        "    rectange, rotate_angle = sort_rectangle(FLAGS, rectange)\n",
        "\n",
        "    p0_rect, p1_rect, p2_rect, p3_rect = rectange\n",
        "    for y, x in xy_in_poly:\n",
        "      point = np.array([x, y], dtype=np.float32)\n",
        "      # top\n",
        "      geo_map[y, x, 0] = point_dist_to_line(p0_rect, p1_rect, point)\n",
        "      # right\n",
        "      geo_map[y, x, 1] = point_dist_to_line(p1_rect, p2_rect, point)\n",
        "      # down\n",
        "      geo_map[y, x, 2] = point_dist_to_line(p2_rect, p3_rect, point)\n",
        "      # left\n",
        "      geo_map[y, x, 3] = point_dist_to_line(p3_rect, p0_rect, point)\n",
        "      # angle\n",
        "      geo_map[y, x, 4] = rotate_angle\n",
        "\n",
        "  shrinked_poly_mask = (shrinked_poly_mask > 0).astype('uint8')\n",
        "  text_region_boundary_training_mask = 1 - (orig_poly_mask - shrinked_poly_mask)\n",
        "\n",
        "  return score_map, geo_map, overly_small_text_region_training_mask, text_region_boundary_training_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vvl41sbCuHpq"
      },
      "outputs": [],
      "source": [
        "def all(iterable):\n",
        "  for element in iterable:\n",
        "    if not element:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def pad_image(img, input_size, is_train):\n",
        "  new_h, new_w, _ = img.shape\n",
        "  max_h_w_i = np.max([new_h, new_w, input_size])\n",
        "  img_padded = np.zeros((max_h_w_i, max_h_w_i, 3), dtype=np.uint8)\n",
        "  if is_train:\n",
        "    shift_h = np.random.randint(max_h_w_i - new_h + 1)\n",
        "    shift_w = np.random.randint(max_h_w_i - new_w + 1)\n",
        "  else:\n",
        "    shift_h = (max_h_w_i - new_h) // 2\n",
        "    shift_w = (max_h_w_i - new_w) // 2\n",
        "  img_padded[shift_h:new_h+shift_h, shift_w:new_w+shift_w, :] = img.copy()\n",
        "  img = img_padded\n",
        "  return img, shift_h, shift_w\n",
        "\n",
        "def resize_image(img, text_polys, input_size, shift_h, shift_w):\n",
        "  new_h, new_w, _ = img.shape\n",
        "  img = cv2.resize(img, dsize=(input_size, input_size))\n",
        "  # pad and resize text polygons\n",
        "  resize_ratio_3_x = input_size/float(new_w)\n",
        "  resize_ratio_3_y = input_size/float(new_h)\n",
        "  text_polys[:, :, 0] += shift_w\n",
        "  text_polys[:, :, 1] += shift_h\n",
        "  text_polys[:, :, 0] *= resize_ratio_3_x\n",
        "  text_polys[:, :, 1] *= resize_ratio_3_y\n",
        "  return img, text_polys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LQDr6TIDuV5n"
      },
      "outputs": [],
      "source": [
        "class threadsafe_iter:\n",
        "  \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
        "  serializing call to the `next` method of given iterator/generator.\n",
        "  \"\"\"\n",
        "  def __init__(self, it):\n",
        "    self.it = it\n",
        "    self.lock = threading.Lock()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self): # Python 3\n",
        "    with self.lock:\n",
        "      return next(self.it)\n",
        "\n",
        "def threadsafe_generator(f):\n",
        "  \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
        "  \"\"\"\n",
        "  def g(*a, **kw):\n",
        "    return threadsafe_iter(f(*a, **kw))\n",
        "  return g\n",
        "\n",
        "@threadsafe_generator\n",
        "def generator(FLAGS, input_size=512, background_ratio=3./8, is_train=True, idx=None, random_scale=np.array([0.5, 1, 2.0, 3.0]), vis=False):\n",
        "  image_list = np.array(get_images(FLAGS.training_data_path))\n",
        "  if not idx is None:\n",
        "    image_list = image_list[idx]\n",
        "  print('{} training images in {}'.format(\n",
        "    image_list.shape[0], FLAGS.training_data_path))\n",
        "  index = np.arange(0, image_list.shape[0])\n",
        "  epoch = 1\n",
        "  while True:\n",
        "    np.random.shuffle(index)\n",
        "    images = []\n",
        "    image_fns = []\n",
        "    score_maps = []\n",
        "    geo_maps = []\n",
        "    overly_small_text_region_training_masks = []\n",
        "    text_region_boundary_training_masks = []\n",
        "    for i in index:\n",
        "      try:\n",
        "        im_fn = image_list[i]\n",
        "        im = cv2.imread(im_fn)\n",
        "        h, w, _ = im.shape\n",
        "        name_im = im_fn.split(\"/\")[-1]\n",
        "        text_polys, text_tags = load_annotation(FLAGS.training_data_path, name_im)\n",
        "        text_polys, text_tags = check_and_validate_polys(FLAGS, text_polys, text_tags, (h, w))\n",
        "        # random scale this image\n",
        "        rd_scale = np.random.choice(random_scale)\n",
        "        x_scale_variation = np.random.randint(-10, 10) / 100.\n",
        "        y_scale_variation = np.random.randint(-10, 10) / 100.\n",
        "        im = cv2.resize(im, dsize=None, fx=rd_scale + x_scale_variation, fy=rd_scale + y_scale_variation)\n",
        "        text_polys[:, :, 0] *= rd_scale + x_scale_variation\n",
        "        text_polys[:, :, 1] *= rd_scale + y_scale_variation\n",
        "\n",
        "        # random crop a area from image\n",
        "        if np.random.rand() < background_ratio:\n",
        "          # crop background\n",
        "          im, text_polys, text_tags = crop_area(FLAGS, im, text_polys, text_tags, crop_background=True)\n",
        "          if text_polys.shape[0] > 0:\n",
        "            # cannot find background\n",
        "            continue\n",
        "          # pad and resize image\n",
        "          im, _, _ = pad_image(im, FLAGS.input_size, is_train)\n",
        "          im = cv2.resize(im, dsize=(input_size, input_size))\n",
        "          score_map = np.zeros((input_size, input_size), dtype=np.uint8)\n",
        "          geo_map_channels = 5 if FLAGS.geometry == 'RBOX' else 8\n",
        "          geo_map = np.zeros((input_size, input_size, geo_map_channels), dtype=np.float32)\n",
        "          overly_small_text_region_training_mask = np.ones((input_size, input_size), dtype=np.uint8)\n",
        "          text_region_boundary_training_mask = np.ones((input_size, input_size), dtype=np.uint8)\n",
        "        else:\n",
        "          im, text_polys, text_tags = crop_area(FLAGS, im, text_polys, text_tags, crop_background=False)\n",
        "          if text_polys.shape[0] == 0:\n",
        "            continue\n",
        "          h, w, _ = im.shape\n",
        "          im, shift_h, shift_w = pad_image(im, FLAGS.input_size, is_train)\n",
        "          im, text_polys = resize_image(im, text_polys, FLAGS.input_size, shift_h, shift_w)\n",
        "          new_h, new_w, _ = im.shape\n",
        "          score_map, geo_map, overly_small_text_region_training_mask, text_region_boundary_training_mask = generate_rbox(FLAGS, (new_h, new_w), text_polys, text_tags)\n",
        "        im = (im / 127.5) - 1.\n",
        "        images.append(im[:, :, ::-1].astype(np.float32))\n",
        "        image_fns.append(im_fn)\n",
        "        score_maps.append(score_map[::4, ::4, np.newaxis].astype(np.float32))\n",
        "        geo_maps.append(geo_map[::4, ::4, :].astype(np.float32))\n",
        "        overly_small_text_region_training_masks.append(overly_small_text_region_training_mask[::4, ::4, np.newaxis].astype(np.float32))\n",
        "        text_region_boundary_training_masks.append(text_region_boundary_training_mask[::4, ::4, np.newaxis].astype(np.float32))\n",
        "        if len(images) == FLAGS.batch_size:\n",
        "          yield [np.array(images), np.array(overly_small_text_region_training_masks), np.array(text_region_boundary_training_masks), np.array(score_maps)], [np.array(score_maps), np.array(geo_maps)]\n",
        "          images = []\n",
        "          image_fns = []\n",
        "          score_maps = []\n",
        "          geo_maps = []\n",
        "          overly_small_text_region_training_masks = []\n",
        "          text_region_boundary_training_masks = []\n",
        "      except Exception as e:\n",
        "        import traceback\n",
        "        if not FLAGS.suppress_warnings_and_error_messages:\n",
        "          traceback.print_exc()\n",
        "        continue\n",
        "    epoch += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBf8LmaCvMfO"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wRszhsI9kU4W"
      },
      "outputs": [],
      "source": [
        "RESIZE_FACTOR = 2\n",
        "\n",
        "def resize_bilinear(x):\n",
        "  return tf.compat.v1.image.resize_bilinear(x, size=[tf.shape(x)[1] * RESIZE_FACTOR, tf.shape(x)[2] * RESIZE_FACTOR])\n",
        "\n",
        "def resize_output_shape(input_shape):\n",
        "  shape = list(input_shape)\n",
        "  assert len(shape) == 4\n",
        "  shape[1] *= RESIZE_FACTOR\n",
        "  shape[2] *= RESIZE_FACTOR\n",
        "  return tuple(shape)\n",
        "\n",
        "class EAST_model(tf.keras.Model):\n",
        "  def __init__(self, input_size=512):\n",
        "    super(EAST_model, self).__init__()\n",
        "\n",
        "    input_image = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')\n",
        "    overly_small_text_region_training_mask = tf.keras.layers.Input(shape=(None, None, 1), name='overly_small_text_region_training_mask')\n",
        "    text_region_boundary_training_mask = tf.keras.layers.Input(shape=(None, None, 1), name='text_region_boundary_training_mask')\n",
        "    target_score_map = tf.keras.layers.Input(shape=(None, None, 1), name='target_score_map')\n",
        "    resnet = tf.keras.applications.ResNet50(input_tensor=input_image, weights='imagenet', include_top=False, pooling=None)\n",
        "    x = resnet.get_layer('conv5_block3_out').output\n",
        "\n",
        "    x = tf.keras.layers.Lambda(resize_bilinear, name='resize_1')(x)\n",
        "    x = tf.keras.layers.concatenate([x, resnet.get_layer('conv4_block6_out').output], axis=3)\n",
        "    x = tf.keras.layers.Conv2D(128, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Lambda(resize_bilinear, name='resize_2')(x)\n",
        "    x = tf.keras.layers.concatenate([x, resnet.get_layer('conv3_block4_out').output], axis=3)\n",
        "    x = tf.keras.layers.Conv2D(64, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Lambda(resize_bilinear, name='resize_3')(x)\n",
        "    x = tf.keras.layers.concatenate([x, resnet.get_layer('conv2_block3_out').output], axis=3)\n",
        "    x = tf.keras.layers.Conv2D(32, (1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.997, epsilon=1e-5, scale=True)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    pred_score_map = tf.keras.layers.Conv2D(1, (1, 1), activation=tf.nn.sigmoid, name='pred_score_map')(x)\n",
        "    rbox_geo_map = tf.keras.layers.Conv2D(4, (1, 1), activation=tf.nn.sigmoid, name='rbox_geo_map')(x)\n",
        "    rbox_geo_map = tf.keras.layers.Lambda(lambda x: x * input_size)(rbox_geo_map)\n",
        "    angle_map = tf.keras.layers.Conv2D(1, (1, 1), activation=tf.nn.sigmoid, name='rbox_angle_map')(x)\n",
        "    angle_map = tf.keras.layers.Lambda(lambda x: (x - 0.5) * np.pi / 2)(angle_map)\n",
        "    pred_geo_map = tf.keras.layers.concatenate([rbox_geo_map, angle_map], axis=3, name='pred_geo_map')\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_image], outputs=[pred_score_map, pred_geo_map])\n",
        "\n",
        "    self.model = model\n",
        "    self.input_image = input_image\n",
        "    self.overly_small_text_region_training_mask = overly_small_text_region_training_mask\n",
        "    self.text_region_boundary_training_mask = text_region_boundary_training_mask\n",
        "    self.target_score_map = target_score_map\n",
        "    self.pred_score_map = pred_score_map\n",
        "    self.pred_geo_map = pred_geo_map\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma7jdj_bvW-F"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "imbbk_JZkVoO"
      },
      "outputs": [],
      "source": [
        "flags = tf.compat.v1.app.flags\n",
        "flags.DEFINE_string('gpu_num', default='1', help='gpu number to run')\n",
        "flags.DEFINE_string('test_data_path', default='./Products-Real/evaluation', help='test data path')\n",
        "flags.DEFINE_string('model_path', default='./east_resnet_50_rbox/', help='trained model saved path')\n",
        "flags.DEFINE_string('output_dir', default='./output/', help='test data output path')\n",
        "flags.DEFINE_integer('input_size', default=512, help='input size for training of the network')\n",
        "flags.DEFINE_integer('batch_size', default=8, help='batch size for training')\n",
        "flags.DEFINE_integer('nb_workers', default=4, help='number of processes to spin up when using process based threading') # as defined in https://keras.io/models/model/#fit_generator\n",
        "flags.DEFINE_float('init_learning_rate', default=0.0001, help='initial learning rate')\n",
        "flags.DEFINE_float('lr_decay_rate', default=0.94, help='decay rate for the learning rate')\n",
        "flags.DEFINE_integer('lr_decay_steps', default=16250, help='number of steps after which the learning rate is decayed by decay rate')\n",
        "flags.DEFINE_integer('max_steps', default=100000, help='maximum number of steps')\n",
        "flags.DEFINE_string('checkpoint_path', default='./east_resnet_50_rbox', help='path to a directory to save model checkpoints during training')\n",
        "flags.DEFINE_integer('save_checkpoint_steps', default=50, help='period at which checkpoints are saved (defaults to every 50 steps)')\n",
        "flags.DEFINE_string('training_data_path', default='./Products-Real/train', help='path to training data')\n",
        "flags.DEFINE_integer('max_image_large_side', default=1280, help='maximum size of the large side of a training image before cropping a patch for training')\n",
        "flags.DEFINE_integer('max_text_size', default=800, help='maximum size of a text instance in an image; image resized if this limit is exceeded')\n",
        "flags.DEFINE_integer('min_text_size', default=10, help='minimum size of a text instance; if smaller, then it is ignored during training')\n",
        "flags.DEFINE_float('min_crop_side_ratio', default=0.1, help='the minimum ratio of min(H, W), the smaller side of the image, when taking a random crop from thee input image')\n",
        "flags.DEFINE_string('geometry', default='RBOX', help='geometry type to be used; only RBOX is implemented now, but the original paper also uses QUAD')\n",
        "flags.DEFINE_boolean('suppress_warnings_and_error_messages', default=True, help='whether to show error messages and warnings during training (some error messages during training are expected to appear because of the way patches for training are created)')\n",
        "FLAGS = flags.FLAGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1qOamH1udJk"
      },
      "outputs": [],
      "source": [
        "def train_step(model,\n",
        "               x,\n",
        "               optimizer,\n",
        "               overly_small_text_region_training_mask,\n",
        "               text_region_boundary_training_mask,\n",
        "               small_text_weight,\n",
        "               target_score_map,\n",
        "               target_geo_maps,\n",
        "               loss_weight):\n",
        "  with tf.GradientTape() as tape:\n",
        "    score_y_pred, geo_y_pred = model(x)\n",
        "    _dice_loss = dice_loss(overly_small_text_region_training_mask, text_region_boundary_training_mask, loss_weight, small_text_weight, target_score_map, score_y_pred)\n",
        "    _rbox_loss = rbox_loss(overly_small_text_region_training_mask, text_region_boundary_training_mask, small_text_weight, target_score_map, target_geo_maps, geo_y_pred)\n",
        "    loss = _dice_loss + _rbox_loss\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "\n",
        "def main(_):\n",
        "  # check if checkpoint path exists\n",
        "  if not os.path.exists(FLAGS.checkpoint_path):\n",
        "    os.mkdir(FLAGS.checkpoint_path)\n",
        "\n",
        "  train_data_generator = generator(FLAGS)\n",
        "\n",
        "  east = EAST_model(FLAGS.input_size)\n",
        "  east.model.summary()\n",
        "\n",
        "  score_map_loss_weight = tf.Variable(0.01, name='score_map_loss_weight')\n",
        "  small_text_weight = tf.Variable(0., name='small_text_weight')\n",
        "\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    FLAGS.init_learning_rate,\n",
        "    decay_steps=FLAGS.lr_decay_steps,\n",
        "    decay_rate=FLAGS.lr_decay_rate,\n",
        "    staircase=True)\n",
        "\n",
        "  optimizer = tf.optimizers.Adam(lr_schedule)\n",
        "\n",
        "  # set checkpoint manager\n",
        "  ckpt = tf.train.Checkpoint(step=tf.Variable(0), model=east)\n",
        "  ckpt_manager = tf.train.CheckpointManager(ckpt,\n",
        "                                            directory=FLAGS.checkpoint_path,\n",
        "                                            max_to_keep=5)\n",
        "  latest_ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\n",
        "\n",
        "  # restore latest checkpoint\n",
        "  if latest_ckpt:\n",
        "    ckpt.restore(latest_ckpt)\n",
        "    print('global_step : {}, checkpoint is restored!'.format(int(ckpt.step)))\n",
        "\n",
        "  # set tensorboard summary writer\n",
        "  summary_writer = tf.summary.create_file_writer(FLAGS.checkpoint_path + '/train')\n",
        "\n",
        "  while int(ckpt.step) < (FLAGS.max_steps + 1):\n",
        "    # load data\n",
        "    [input_images, overly_small_text_region_training_masks, text_region_boundary_training_masks, score_maps], \\\n",
        "    [target_score_maps, target_geo_maps] = next(train_data_generator)\n",
        "\n",
        "    # update parameter\n",
        "    train_step(east,\n",
        "               input_images,\n",
        "               optimizer,\n",
        "               overly_small_text_region_training_masks,\n",
        "               text_region_boundary_training_masks,\n",
        "               small_text_weight,\n",
        "               target_score_maps,\n",
        "               target_geo_maps,\n",
        "               score_map_loss_weight\n",
        "               )\n",
        "\n",
        "    score_y_pred, geo_y_pred = east(input_images)\n",
        "    _dice_loss = dice_loss(overly_small_text_region_training_masks, text_region_boundary_training_masks, score_map_loss_weight,\n",
        "                           small_text_weight, target_score_maps, score_y_pred)\n",
        "    _rbox_loss = rbox_loss(overly_small_text_region_training_masks, text_region_boundary_training_masks,\n",
        "                           small_text_weight, target_score_maps, target_geo_maps, geo_y_pred)\n",
        "    loss = _dice_loss + _rbox_loss\n",
        "\n",
        "    print('Step {:06d}, dice_loss {:.4f}, rbox_loss {:.4f}, total_loss {:.4f}'.format(int(ckpt.step), _dice_loss, _rbox_loss, loss))\n",
        "\n",
        "    if ckpt.step % FLAGS.save_checkpoint_steps == 0:\n",
        "      # save checkpoint\n",
        "      ckpt_manager.save(checkpoint_number=ckpt.step)\n",
        "      print('global_step : {}, checkpoint is saved!'.format(int(ckpt.step)))\n",
        "\n",
        "      with summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', loss, step=int(ckpt.step))\n",
        "        tf.summary.scalar('pred_score_map_loss', _dice_loss, step=int(ckpt.step))\n",
        "        tf.summary.scalar('pred_geo_map_loss ', _rbox_loss, step=int(ckpt.step))\n",
        "        tf.summary.scalar('learning_rate ', optimizer.lr(ckpt.step).numpy(), step=int(ckpt.step))\n",
        "        tf.summary.scalar('small_text_weight', small_text_weight, step=int(ckpt.step))\n",
        "\n",
        "        tf.summary.image(\"input_image\", tf.cast((input_images + 1) * 127.5, tf.uint8), step=int(ckpt.step), max_outputs=3)\n",
        "        tf.summary.image(\"overly_small_text_region_training_mask\", tf.cast(overly_small_text_region_training_masks * 255, tf.uint8), step=int(ckpt.step), max_outputs=3)\n",
        "        tf.summary.image(\"text_region_boundary_training_mask\", tf.cast(text_region_boundary_training_masks * 255, tf.uint8), step=int(ckpt.step), max_outputs=3)\n",
        "        tf.summary.image(\"score_map_target\", tf.cast(target_score_maps * 255, tf.uint8), step=int(ckpt.step), max_outputs=3)\n",
        "        tf.summary.image(\"score_map_pred\", tf.cast(score_y_pred * 255, tf.uint8), step=int(ckpt.step), max_outputs=3)\n",
        "        for i in range(4):\n",
        "          tf.summary.image(\"geo_map_%d_target\" % (i), tf.cast(tf.expand_dims(target_geo_maps[:, :, :, i], axis=3) / FLAGS.input_size * 255, tf.uint8), step=int(ckpt.step), max_outputs=3)\n",
        "          tf.summary.image(\"geo_map_%d_pred\" % (i), tf.cast(tf.expand_dims(geo_y_pred[:, :, :, i], axis=3) / FLAGS.input_size * 255, tf.uint8), step=int(ckpt.step), max_outputs=3)\n",
        "        tf.summary.image(\"geo_map_4_target\", tf.cast((tf.expand_dims(target_geo_maps[:, :, :, 4], axis=3) + 1) * 127.5, tf.uint8), step=int(ckpt.step), max_outputs=3)\n",
        "        tf.summary.image(\"geo_map_4_pred\", tf.cast((tf.expand_dims(geo_y_pred[:, :, :, 4], axis=3) + 1) * 127.5, tf.uint8), step=int(ckpt.step), max_outputs=3)\n",
        "\n",
        "    ckpt.step.assign_add(1)\n",
        "\n",
        "tf.compat.v1.app.run(main)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAfSL-_xw5nX"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3U-Rp8HkV6A"
      },
      "outputs": [],
      "source": [
        "flags.DEFINE_string('gpu_num', default='1', help='gpu number to run')\n",
        "flags.DEFINE_string('test_data_path', default='./data/ICDAR2015/test_data', help='test data path')\n",
        "flags.DEFINE_string('model_path', default='./east_resnet_50_rbox/', help='trained model saved path')\n",
        "flags.DEFINE_string('output_dir', default='./data/ICDAR2015/test_data_output/', help='test data output path')\n",
        "FLAGS = flags.FLAGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OdR7s_bufDM"
      },
      "outputs": [],
      "source": [
        "def resize_image_test(im, max_side_len=2400):\n",
        "  '''\n",
        "  resize image to a size multiple of 32 which is required by the network\n",
        "  :param im: the resized image\n",
        "  :param max_side_len: limit of max image size to avoid out of memory in gpu\n",
        "  :return: the resized image and the resize ratio\n",
        "  '''\n",
        "  h, w, _ = im.shape\n",
        "\n",
        "  resize_w = w\n",
        "  resize_h = h\n",
        "\n",
        "  # limit the max side\n",
        "  if max(resize_h, resize_w) > max_side_len:\n",
        "    ratio = float(max_side_len) / resize_h if resize_h > resize_w else float(max_side_len) / resize_w\n",
        "  else:\n",
        "    ratio = 1.\n",
        "  resize_h = int(resize_h * ratio)\n",
        "  resize_w = int(resize_w * ratio)\n",
        "\n",
        "  resize_h = resize_h if resize_h % 32 == 0 else (resize_h // 32) * 32\n",
        "  resize_w = resize_w if resize_w % 32 == 0 else (resize_w // 32) * 32\n",
        "  im = cv2.resize(im, (int(resize_w), int(resize_h)))\n",
        "\n",
        "  ratio_h = resize_h / float(h)\n",
        "  ratio_w = resize_w / float(w)\n",
        "\n",
        "  return im, (ratio_h, ratio_w)\n",
        "\n",
        "\n",
        "def detect(score_map, geo_map, timer, score_map_thresh=0.8, box_thresh=0.1, nms_thres=0.2):\n",
        "  '''\n",
        "  restore text boxes from score map and geo map\n",
        "  :param score_map:\n",
        "  :param geo_map:\n",
        "  :param timer:\n",
        "  :param score_map_thresh: threshhold for score map\n",
        "  :param box_thresh: threshhold for boxes\n",
        "  :param nms_thres: threshold for nms\n",
        "  :return:\n",
        "  '''\n",
        "  if len(score_map.shape) == 4:\n",
        "    score_map = score_map[0, :, :, 0]\n",
        "    geo_map = geo_map[0, :, :, ]\n",
        "  # filter the score map\n",
        "  xy_text = np.argwhere(score_map > score_map_thresh)\n",
        "  # sort the text boxes via the y axis\n",
        "  xy_text = xy_text[np.argsort(xy_text[:, 0])]\n",
        "  # restore\n",
        "  start = time.time()\n",
        "  text_box_restored = restore_rectangle(xy_text[:, ::-1]*4, geo_map[xy_text[:, 0], xy_text[:, 1], :]) # N*4*2\n",
        "  print('{} text boxes before nms'.format(text_box_restored.shape[0]))\n",
        "  boxes = np.zeros((text_box_restored.shape[0], 9), dtype=np.float32)\n",
        "  boxes[:, :8] = text_box_restored.reshape((-1, 8))\n",
        "  boxes[:, 8] = score_map[xy_text[:, 0], xy_text[:, 1]]\n",
        "  timer['restore'] = time.time() - start\n",
        "  # nms part\n",
        "  start = time.time()\n",
        "  # boxes = nms_locality.nms_locality(boxes.astype(np.float64), nms_thres)\n",
        "  boxes = la_nms(boxes.astype('float32'), nms_thres)\n",
        "  timer['nms'] = time.time() - start\n",
        "\n",
        "  if boxes.shape[0] == 0:\n",
        "    return None, timer\n",
        "\n",
        "  # here we filter some low score boxes by the average score map, this is different from the orginal paper\n",
        "  for i, box in enumerate(boxes):\n",
        "    mask = np.zeros_like(score_map, dtype=np.uint8)\n",
        "    cv2.fillPoly(mask, box[:8].reshape((-1, 4, 2)).astype(np.int32) // 4, 1)\n",
        "    boxes[i, 8] = cv2.mean(score_map, mask)[0]\n",
        "  boxes = boxes[boxes[:, 8] > box_thresh]\n",
        "\n",
        "  return boxes, timer\n",
        "\n",
        "\n",
        "def sort_poly(p):\n",
        "  min_axis = np.argmin(np.sum(p, axis=1))\n",
        "  p = p[[min_axis, (min_axis+1)%4, (min_axis+2)%4, (min_axis+3)%4]]\n",
        "  if abs(p[0, 0] - p[1, 0]) > abs(p[0, 1] - p[1, 1]):\n",
        "    return p\n",
        "  else:\n",
        "    return p[[0, 3, 2, 1]]\n",
        "\n",
        "\n",
        "def test(_):\n",
        "  os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu_num\n",
        "\n",
        "  try:\n",
        "    os.makedirs(FLAGS.output_dir)\n",
        "  except OSError as e:\n",
        "    if e.errno != 17:\n",
        "      raise\n",
        "\n",
        "  # load trained model\n",
        "  model = EAST_model()\n",
        "\n",
        "  ckpt = tf.train.Checkpoint(step=tf.Variable(0), model=model)\n",
        "  latest_ckpt = tf.train.latest_checkpoint(FLAGS.model_path)\n",
        "\n",
        "  if latest_ckpt:\n",
        "    ckpt.restore(latest_ckpt)\n",
        "    print('global_step : {}, checkpoint is restored!'.format(int(ckpt.step)))\n",
        "\n",
        "  img_list = get_images(FLAGS.training_data_path)\n",
        "  for img_file in img_list:\n",
        "    img = cv2.imread(img_file)[:, :, ::-1]\n",
        "    start_time = time.time()\n",
        "    img_resized, (ratio_h, ratio_w) = resize_image_test(img)\n",
        "\n",
        "    img_resized = (img_resized / 127.5) - 1\n",
        "\n",
        "    timer = {'net': 0, 'restore': 0, 'nms': 0}\n",
        "    start = time.time()\n",
        "\n",
        "    # feed image into model\n",
        "    score_map, geo_map = model.predict(img_resized[np.newaxis, :, :, :])\n",
        "\n",
        "    timer['net'] = time.time() - start\n",
        "\n",
        "    boxes, timer = detect(score_map=score_map, geo_map=geo_map, timer=timer)\n",
        "\n",
        "    print('{} : net {:.0f}ms, restore {:.0f}ms, nms {:.0f}ms'.format(\n",
        "      img_file, timer['net']*1000, timer['restore']*1000, timer['nms']*1000))\n",
        "\n",
        "    if boxes is not None:\n",
        "      boxes = boxes[:, :8].reshape((-1, 4, 2))\n",
        "      boxes[:, :, 0] /= ratio_w\n",
        "      boxes[:, :, 1] /= ratio_h\n",
        "\n",
        "    duration = time.time() - start_time\n",
        "    print('[timing] {}'.format(duration))\n",
        "\n",
        "    # save to file\n",
        "    if boxes is not None:\n",
        "      res_file = os.path.join(\n",
        "        FLAGS.output_dir,\n",
        "        '{}.txt'.format(\n",
        "          os.path.basename(img_file).split('.')[0]))\n",
        "\n",
        "      with open(res_file, 'w') as f:\n",
        "        for box in boxes:\n",
        "          # to avoid submitting errors\n",
        "          box = sort_poly(box.astype(np.int32))\n",
        "          if np.linalg.norm(box[0] - box[1]) < 5 or np.linalg.norm(box[3]-box[0]) < 5:\n",
        "            continue\n",
        "          f.write('{},{},{},{},{},{},{},{}\\r\\n'.format(\n",
        "            box[0, 0], box[0, 1], box[1, 0], box[1, 1], box[2, 0], box[2, 1], box[3, 0], box[3, 1],\n",
        "          ))\n",
        "          cv2.polylines(img[:, :, ::-1], [box.astype(np.int32).reshape((-1, 1, 2))], True, color=(255, 255, 0), thickness=1)\n",
        "\n",
        "    img_path = os.path.join(FLAGS.output_dir, os.path.basename(img_file))\n",
        "    cv2.imwrite(img_path, img[:, :, ::-1])\n",
        "\n",
        "tf.compat.v1.app.run(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSLSJufk_PvC"
      },
      "source": [
        "## Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBrWKHKE_PEg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h-acSE1uW73"
      },
      "source": [
        "# Text Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuypSYoUIneq"
      },
      "outputs": [],
      "source": [
        "class ModelConfigs(BaseModelConfigs):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model_path = os.path.join(\"./Models/1_image_to_word\", datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"))\n",
        "        self.vocab = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
        "        self.height = 32\n",
        "        self.width = 128\n",
        "        self.max_text_length = 23\n",
        "        self.batch_size = 1500\n",
        "        self.learning_rate = 1e-4\n",
        "        self.train_epochs = 15\n",
        "        self.train_workers = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40I0JKz3n5dc"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34dCinGsHd8b"
      },
      "outputs": [],
      "source": [
        "configs = ModelConfigs()\n",
        "\n",
        "date_path_synth = \"Date-Synth\"\n",
        "annotation_date_synth = date_path_synth + \"/annotations.json\"\n",
        "date_path_real = \"Date-Real\"\n",
        "annotation_date_real = date_path_real + \"/annotations.json\"\n",
        "\n",
        "# Read metadata file and parse it\n",
        "def read_annotation_file(data_path, annotation_path):\n",
        "    dataset, vocab, max_len = [], set(), 0\n",
        "    with open(annotation_path) as f:\n",
        "        data = json.load (f)\n",
        "        for line in tqdm(data):\n",
        "            image_path = data_path + \"/images/\" + line\n",
        "            label = ''\n",
        "            for num in data[line]['ann']:\n",
        "              label += num['transcription'] + \" \"\n",
        "            label = label.strip()\n",
        "            dataset.append([image_path,label])\n",
        "            vocab.update(list(label))\n",
        "            max_len = max(max_len,len(label))\n",
        "    return dataset, sorted(vocab), max_len\n",
        "\n",
        "train_dataset, train_vocab, max_train_len = read_annotation_file(date_path_synth, annotation_date_synth)\n",
        "val_dataset, val_vocab, max_val_len = read_annotation_file(date_path_real, annotation_date_real)\n",
        "\n",
        "# Save vocab and maximum text length to configs\n",
        "configs.vocab = \"\".join(train_vocab)\n",
        "configs.max_text_length = max(max_train_len, max_val_len)\n",
        "\n",
        "# If BaseModelConfigs doesn't have a save method, you might need to save the configurations manually.\n",
        "# For example, you could write them to a file:\n",
        "with open('configs.json', 'w') as f:\n",
        "    json.dump({'vocab': configs.vocab, 'max_text_length': configs.max_text_length}, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qc0TTJbHhLd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create training data provider\n",
        "train_data_provider = DataProvider(\n",
        "    dataset=train_dataset,\n",
        "    skip_validation=True,\n",
        "    batch_size=configs.batch_size,\n",
        "    data_preprocessors=[ImageReader()],\n",
        "    transformers=[\n",
        "        ImageResizer(configs.width, configs.height),\n",
        "        LabelIndexer(configs.vocab),\n",
        "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab))\n",
        "        ],\n",
        ")\n",
        "\n",
        "# Create validation data provider\n",
        "val_data_provider = DataProvider(\n",
        "    dataset=val_dataset,\n",
        "    skip_validation=True,\n",
        "    batch_size=configs.batch_size,\n",
        "    data_preprocessors=[ImageReader()],\n",
        "    transformers=[\n",
        "        ImageResizer(configs.width, configs.height),\n",
        "        LabelIndexer(configs.vocab),\n",
        "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab))\n",
        "        ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksamz3k1oOYs"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxhcDuLME0fw"
      },
      "outputs": [],
      "source": [
        "def train_model(input_dim, output_dim, activation='leaky_relu', dropout=0.2):\n",
        "\n",
        "    inputs = layers.Input(shape=input_dim, name=\"input\")\n",
        "\n",
        "    input = layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "    x1 = residual_block(input, 16, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
        "\n",
        "    x2 = residual_block(x1, 16, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
        "    x3 = residual_block(x2, 16, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
        "\n",
        "    x4 = residual_block(x3, 32, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
        "    x5 = residual_block(x4, 32, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
        "\n",
        "    x6 = residual_block(x5, 64, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
        "    x7 = residual_block(x6, 64, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
        "\n",
        "    squeezed = layers.Reshape((x7.shape[-3] * x7.shape[-2], x7.shape[-1]))(x7)\n",
        "\n",
        "    blstm = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(squeezed)\n",
        "\n",
        "    output = layers.Dense(output_dim + 1, activation='softmax', name=\"output\")(blstm)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI0XeQYlZIog"
      },
      "outputs": [],
      "source": [
        "# Define learning_rate\n",
        "configs.learning_rate = 0.001\n",
        "model = train_model(\n",
        "    input_dim = (configs.height, configs.width, 3),\n",
        "    output_dim = len(configs.vocab),\n",
        ")\n",
        "\n",
        "# Compile the model and print summary\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=configs.learning_rate),\n",
        "    loss=CTCloss(),\n",
        "    metrics=[CWERMetric()],\n",
        "    run_eagerly=False\n",
        ")\n",
        "model.summary(line_length=110)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmilIZ2VoREs"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3u2ie5jFWJL"
      },
      "outputs": [],
      "source": [
        "# Create necessary directories\n",
        "os.makedirs(configs.model_path, exist_ok=True)\n",
        "\n",
        "# Define callbacks\n",
        "earlystopper = EarlyStopping(monitor='val_CER', patience=10, verbose=1)\n",
        "checkpoint = ModelCheckpoint(f\"{configs.model_path}/model.h5\", monitor='val_CER', verbose=1, save_best_only=True, mode='min')\n",
        "trainLogger = TrainLogger(configs.model_path)\n",
        "tb_callback = TensorBoard(f'{configs.model_path}/logs', update_freq=1)\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_CER', factor=0.9, min_delta=1e-10, patience=5, verbose=1, mode='auto')\n",
        "model2onnx = Model2onnx(f\"{configs.model_path}/model.h5\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_data_provider,\n",
        "    validation_data=val_data_provider,\n",
        "    epochs=configs.train_epochs,\n",
        "    callbacks=[earlystopper, checkpoint, trainLogger, reduceLROnPlat, tb_callback, model2onnx],\n",
        "    workers=configs.train_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BncDDxrZRjhv"
      },
      "outputs": [],
      "source": [
        "!tensorboard --logdir Models/1_image_to_word/202211270035/logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQZXSlAEZg6m"
      },
      "outputs": [],
      "source": [
        "# Save training and validation datasets as csv files\n",
        "train_data_provider.to_csv(os.path.join(configs.model_path, \"train.csv\"))\n",
        "val_data_provider.to_csv(os.path.join(configs.model_path, \"val.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfqH30P-oSu-"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmhx-Ig2_Cp7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4H22vhGp0oy"
      },
      "source": [
        "## Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71pHbVK-p4V6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
